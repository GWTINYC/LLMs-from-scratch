{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45398736-7e89-4263-89c8-92153baff553",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "<a href=\"https://sebastianraschka.com\">Sebastian Raschka</a> 撰写的 <a href=\"http://mng.bz/orYv\">《从零构建大语言模型》</a> (Build a Large Language Model From Scratch) 书籍的补充代码<br>\n",
    "<br>代码仓库：<a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
   "metadata": {
    "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
   },
   "source": [
    "# 第 5 章：在无标签数据上进行预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b989e9-da36-4159-b212-799184764dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.7\n",
      "numpy version: 2.3.4\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.9.0\n",
      "tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
   "metadata": {},
   "source": [
    "- 在本章中，我们将实现用于预训练 LLM 的训练循环和基本模型评估代码\n",
    "- 在本章的最后，我们将从 OpenAI 加载公开可用的预训练权重到我们的模型中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/01.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214765-7a73-42d5-95e9-302154b29db9",
   "metadata": {},
   "source": [
    "- 本章涵盖的主题如下所示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/02.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
   "metadata": {
    "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
   },
   "source": [
    "## 5.1 评估生成式文本模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
   "metadata": {},
   "source": [
    "- 本节开始时，我们将简要回顾如何使用上一章的代码初始化 GPT 模型\n",
    "- 然后，我们讨论 LLM 的基本评估指标\n",
    "- 最后，在本节中，我们将这些评估指标应用于训练和验证数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
   "metadata": {
    "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
   },
   "source": [
    "### 5.1.1 使用 GPT 生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
   "metadata": {},
   "source": [
    "- 我们使用上一章的代码初始化一个 GPT 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86000d74-624a-48f0-86da-f41926cb9e04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86000d74-624a-48f0-86da-f41926cb9e04",
    "outputId": "ad482cfd-5a62-4f0d-e1e0-008d6457f512"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "# 如果本地没有 `previous_chapters.py` 文件，\n",
    "# 你可以从 `llms-from-scratch` PyPI 包导入它。\n",
    "# 详情请见：https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# 例如：\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # 词表大小\n",
    "    \"context_length\": 256, # 缩短的上下文长度 (这也是原始长度: 1024)\n",
    "    \"emb_dim\": 768,        # 嵌入维度\n",
    "    \"n_heads\": 12,         # 注意力头数\n",
    "    \"n_layers\": 12,        # 层数\n",
    "    \"drop_rate\": 0.1,      # Dropout 率\n",
    "    \"qkv_bias\": False      # Query-key-value 偏置\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # 在推理期间禁用 dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
   "metadata": {},
   "source": [
    "- 我们在上面使用了 0.1 的 dropout，但现在训练 LLM 时不使用 dropout 已经相对普遍了\n",
    "- 现代 LLM 在查询、键和值矩阵的 `nn.Linear` 层中也不使用偏置向量（不同于早期的 GPT 模型），这是通过设置 `\"qkv_bias\": False` 来实现的\n",
    "- 我们将上下文长度（`context_length`）减少到仅 256 个 token，以减少训练模型所需的计算资源，而原始的 1.24 亿参数 GPT-2 模型使用了 1024 个 token\n",
    "  - 这样做是为了让更多的读者能够在他们的笔记本电脑上跟随并执行代码示例\n",
    "  - 但是，请随意将 `context_length` 增加到 1024 个 token（这不需要任何代码更改）\n",
    "  - 我们稍后还将从预训练权重加载一个 `context_length` 为 1024 的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
   "metadata": {},
   "source": [
    "- 接下来，我们使用上一章的 `generate_text_simple` 函数来生成文本\n",
    "- 此外，我们定义了两个便捷函数 `text_to_token_ids` 和 `token_ids_to_text`，用于在本章中使用的 token 和文本表示之间进行转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/03.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "# 或者：\n",
    "# from llms_from_scratch.ch04 import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # 添加 batch 维度\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # 移除 batch 维度\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
   "metadata": {},
   "source": [
    "- 如上所示，模型并没有生成好的文本，因为它还没有经过训练\n",
    "- 我们如何以数值形式衡量或捕捉什么是“好文本”，以便在训练期间对其进行跟踪？\n",
    "- 下一小节将介绍计算生成输出的损失度量的指标，我们可以用它来衡量训练进度\n",
    "- 接下来的微调 LLM 章节还将介绍衡量模型质量的其他方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f9e1a-7bf7-40d8-b1fa-eacabdee8d8e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
   "metadata": {
    "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
   },
   "source": [
    "### 5.1.2 计算文本生成损失：交叉熵和困惑度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
   "metadata": {},
   "source": [
    "- 假设我们有一个 `inputs` 张量，其中包含 2 个训练示例（行）的 token ID\n",
    "- 与 `inputs` 对应，`targets` 包含我们希望模型生成的期望 token ID\n",
    "- 请注意，`targets` 是 `inputs` 向后移动 1 个位置的结果，正如我们在第 2 章实现数据加载器时所解释的那样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
    "outputId": "8d6fa0ff-7b37-4634-c3f0-2c050cbe81f0"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
   "metadata": {},
   "source": [
    "- 将 `inputs` 输入模型，我们获得 2 个输入示例的 logits 向量，每个示例包含 3 个 token\n",
    "- 每个 token 都是一个 50,257 维的向量，对应于词表的大小\n",
    "- 应用 softmax 函数，我们可以将 logits 张量转换为包含概率分数的相同维度的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # 词表中每个 token 的概率\n",
    "print(probas.shape) # 形状: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
   "metadata": {},
   "source": [
    "- 下图使用一个非常小的词表进行说明，概述了我们如何将概率分数转换回文本，这我们在上一章末尾讨论过"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/04.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8480efd-d419-4954-9ecc-2876055334bd",
   "metadata": {},
   "source": [
    "- 正如上一章所讨论的，我们可以应用 `argmax` 函数将概率分数转换为预测的 token ID\n",
    "-上面的 softmax 函数为每个 token 生成了一个 50,257 维的向量；`argmax` 函数返回该向量中概率分数最高的位置，即给定 token 的预测 token ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
   "metadata": {},
   "source": [
    "- 由于我们有 2 个输入 batch，每个 batch 包含 3 个 token，因此我们获得 2 x 3 个预测的 token ID："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
    "outputId": "ed17da47-c3e7-4775-fd00-4ec5bcda3db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4072c-21ed-4df7-8721-dd2535362573",
   "metadata": {},
   "source": [
    "- 如果我们要解码这些 token，我们会发现它们与我们希望模型预测的 token（即目标 token）截然不同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
   "metadata": {},
   "source": [
    "- 这是因为模型还没有经过训练\n",
    "- 要训练模型，我们需要知道它距离正确预测（目标）还有多远"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/06.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7251bf5-a079-4782-901d-68c9225d3157",
   "metadata": {},
   "source": [
    "- 对应于目标索引的 token 概率如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
    "outputId": "41c946a2-c458-433e-a53d-5e7e89d9dddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
   "metadata": {},
   "source": [
    "- 我们希望最大化所有这些值，使它们接近概率 1\n",
    "- 在数学优化中，最大化概率分数的对数比最大化概率分数本身更容易；这超出了本书的范围，但我在此录制了一个更详细的讲座：[L8.2 逻辑回归损失函数](https://www.youtube.com/watch?v=GxJe0DZvydM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
    "outputId": "1bf18e79-1246-4eab-efd8-12b328c78678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# 计算所有 token 概率的对数\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4261441-a511-4633-9c4c-67998af31b84",
   "metadata": {},
   "source": [
    "- 接下来，我们将计算平均对数概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b003797-161b-4d98-81dc-e68320e09fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b003797-161b-4d98-81dc-e68320e09fec",
    "outputId": "a447fe9c-7e27-40ed-f1fb-51210e3f7cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# 计算每个 token 的平均概率\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585",
   "metadata": {},
   "source": [
    "- 我们的目标是通过优化模型权重，使这个平均对数概率尽可能大\n",
    "- 由于使用了对数，最大可能值为 0，而我们目前距离 0 还很远"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514",
   "metadata": {},
   "source": [
    "- 在深度学习中，通常的做法是最小化*负*平均对数概率值，而不是最大化平均对数概率；在我们的例子中，与其最大化 -10.7722 使其接近 0，在深度学习中，我们会最小化 10.7722 使其接近 0\n",
    "- -10.7722 的负值，即 10.7722，在深度学习中也被称为交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
   "metadata": {},
   "source": [
    "- PyTorch 已经实现了一个 `cross_entropy` 函数来执行上述步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/07.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
   "metadata": {},
   "source": [
    "- 在应用 `cross_entropy` 函数之前，让我们检查 logits 和 targets 的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
    "outputId": "43fd802a-8136-4b35-df0d-f61a5d4cb561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits 形状 (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets 形状 (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06",
   "metadata": {},
   "source": [
    "- 对于 PyTorch 中的 `cross_entropy` 函数，我们希望通过在 batch 维度上合并这些张量来将它们展平："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
    "outputId": "0b2b778b-02fb-43b2-c879-adc59055a7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921a57f-3a79-473e-a863-6d63b495010f",
   "metadata": {},
   "source": [
    "- 注意，targets 是 token ID，这也代表了 logits 张量中我们希望最大化的索引位置\n",
    "- PyTorch 中的 `cross_entropy` 函数会自动处理 softmax 的应用和内部对 logits 中那些需要最大化的 token 索引的对数概率计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
    "outputId": "c0be634a-2c65-4ff7-a73f-1bfc2e406ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80",
   "metadata": {},
   "source": [
    "- 与交叉熵损失相关的一个概念是 LLM 的困惑度（Perplexity）\n",
    "- 困惑度仅仅是交叉熵损失的指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "168952a1-b964-4aa7-8e49-966fa26add54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "168952a1-b964-4aa7-8e49-966fa26add54",
    "outputId": "a0a692c1-6412-4068-8aa5-8858548141eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
   "metadata": {},
   "source": [
    "- 困惑度通常被认为更具可解释性，因为它可以被理解为模型在每一步不确定的有效词汇量大小（在上面的例子中，即 48,725 个单词或 token）\n",
    "- 换句话说，困惑度提供了一种衡量标准，说明模型预测的概率分布与数据集中单词的实际分布匹配程度如何\n",
    "- 与损失类似，较低的困惑度表示模型预测更接近实际分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
   "metadata": {
    "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
   },
   "source": [
    "### 5.1.3 计算训练集和验证集的损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
   "metadata": {},
   "source": [
    "- 我们使用一个相对较小的数据集来训练 LLM（实际上，只有一个短篇故事）\n",
    "- 理由如下：\n",
    "  - 你可以在几分钟内在笔记本电脑上运行代码示例，而无需合适的 GPU\n",
    "  - 训练完成得相对较快（几分钟而不是几周），这对教育目的很有好处\n",
    "  - 我们使用公共领域的文本，可以将其包含在这个 GitHub 仓库中，而不会违反任何使用权或导致仓库体积过大\n",
    "\n",
    "\n",
    "- 例如，Llama 2 7B 需要在 A100 GPU 上花费 184,320 个 GPU 小时来训练 2 万亿个 token\n",
    "  - 在撰写本文时，AWS 上一台 8xA100 云服务器的小时成本约为 30 美元\n",
    "  - 因此，通过粗略计算，训练这个 LLM 将花费 184,320 / 8 * 30 美元 = 690,000 美元\n",
    " \n",
    "- 下面，我们使用与第 2 章相同的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    text_data = response.text\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "\n",
    "# 本书最初使用了下面的代码\n",
    "# 但是，urllib 使用的旧协议设置可能会导致\n",
    "# 使用 VPN 的读者遇到问题。\n",
    "# 上面的 `requests` 版本在这方面更加健壮。\n",
    "\n",
    "        \n",
    "# import os\n",
    "# import urllib.request\n",
    "\n",
    "# file_path = \"the-verdict.txt\"\n",
    "# url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         text_data = response.read().decode('utf-8')\n",
    "#     with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "#         file.write(text_data)\n",
    "# else:\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379330f1-80f4-4e34-8724-41d892b04cee",
   "metadata": {},
   "source": [
    "- 通过打印前 99 个和最后 99 个字符，快速检查文本是否加载正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6kgJbe4ehI4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6kgJbe4ehI4q",
    "outputId": "9ff31e88-ee37-47e9-ee64-da6eb552f46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# 前 99 个字符\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j2XPde_ThM_e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "j2XPde_ThM_e",
    "outputId": "a900c1b9-9a87-4078-968b-a5721deda5cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# 最后 99 个字符\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
    "outputId": "c2a25334-21ca-486e-8226-0296e5fc6486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
   "metadata": {},
   "source": [
    "- 只有 5,145 个 token，对于训练 LLM 来说，这段文本非常短，但同样，这是出于教育目的（我们稍后还将加载预训练权重）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
   "metadata": {},
   "source": [
    "- 接下来，我们将数据集分为训练集和验证集，并使用第 2 章中的数据加载器为 LLM 训练准备 batch\n",
    "- 为了便于可视化，下图假设 `max_length=6`，但对于训练加载器，我们将 `max_length` 设置为 LLM 支持的上下文长度\n",
    "- 为简单起见，下图仅显示输入 token\n",
    "    - 由于我们训练 LLM 来预测文本中的下一个单词，因此 targets 看起来与这些 inputs 相同，只是 targets 向后移动了一个位置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/09.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959c855-f860-4358-8b98-bc654f047578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "# 或者：\n",
    "# from llms_from_scratch.ch02 import create_dataloader_v1\n",
    "\n",
    "# 训练/验证比率\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 健全性检查\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"训练加载器没有足够的 token。\"\n",
    "          \"尝试降低 `GPT_CONFIG_124M['context_length']` 或 \"\n",
    "          \"增加 `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"验证加载器没有足够的 token。\"\n",
    "          \"尝试降低 `GPT_CONFIG_124M['context_length']` 或 \"\n",
    "          \"减少 `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
   "metadata": {},
   "source": [
    "- 我们使用相对较小的 batch size 来减少计算资源需求，这也是因为数据集本身就很小\n",
    "- 例如，Llama 2 7B 训练时的 batch size 为 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
   "metadata": {},
   "source": [
    "- 可选检查，确认数据加载正确："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
   "metadata": {},
   "source": [
    "- 另一个可选检查，确认 token 大小在预期范围内："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb860488-5453-41d7-9870-23b723f742a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb860488-5453-41d7-9870-23b723f742a0",
    "outputId": "96b9451a-9557-4126-d1c8-51610a1995ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
   "metadata": {},
   "source": [
    "- 接下来，我们将实现一个实用函数来计算给定 batch 的交叉熵损失\n",
    "- 此外，我们实现第二个实用函数来计算数据加载器中用户指定数量的 batch 的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
   "metadata": {
    "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 如果 num_batches 超过数据加载器中的 batch 总数，\n",
    "        # 则将 batch 数减少到与数据加载器中的 batch 总数相匹配\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
   "metadata": {},
   "source": [
    "- 如果你的机器有支持 CUDA 的 GPU，LLM 将在 GPU 上训练，无需更改任何代码\n",
    "- 通过 `device` 设置，我们确保数据加载到与 LLM 模型相同的设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device.\n",
      "Training loss: 10.987583054436577\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # 使用 PyTorch 2.9 或更高版本获得稳定的 mps 结果\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # nn.Module 类不需要赋值 model = model.to(device)\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # 由于数据加载器中的洗牌，为了可重复性设置种子\n",
    "\n",
    "with torch.no_grad(): # 为了效率禁用梯度跟踪，因为我们还未开始训练\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/10.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
   "metadata": {
    "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
   },
   "source": [
    "## 5.2 训练 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
   "metadata": {},
   "source": [
    "- 在本节中，我们终于实现了训练 LLM 的代码\n",
    "- 我们专注于一个简单的训练函数（如果你有兴趣使用更高级的技术（如学习率预热、余弦退火和梯度裁剪）来增强此训练函数，请参阅[附录 D](../../appendix-D/01_main-chapter-code)）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mtp4gY0ZO-qq",
   "metadata": {
    "id": "Mtp4gY0ZO-qq"
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # 初始化列表以跟踪损失和看到的 token\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # 主训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 将模型设置为训练模式\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # 重置上一次 batch 迭代的损失梯度\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # 计算损失梯度\n",
    "            optimizer.step() # 使用损失梯度更新模型权重\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # 可选评估步骤\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # 在每个 epoch 后打印示例文本\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # 紧凑的打印格式\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
   "metadata": {},
   "source": [
    "- 现在，让我们使用上面定义的训练函数来训练 LLM："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422000b-7aa2-485b-92df-99372cd22311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3422000b-7aa2-485b-92df-99372cd22311",
    "outputId": "0e046603-908d-4093-8ae5-ef2f632639fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.817, Val loss 9.924\n",
      "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.332\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.619, Val loss 7.042\n",
      "Ep 2 (Step 000015): Train loss 6.046, Val loss 6.596\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,, and,, the,, the, and,, and,,, the, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.524, Val loss 6.508\n",
      "Ep 3 (Step 000025): Train loss 5.369, Val loss 6.378\n",
      "Every effort moves you, and to the of the of the picture. Gis.                                     \n",
      "Ep 4 (Step 000030): Train loss 4.830, Val loss 6.263\n",
      "Ep 4 (Step 000035): Train loss 4.586, Val loss 6.285\n",
      "Every effort moves you of the \"I the picture.                    \"I\"I the picture\"I had the picture\"I the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.879, Val loss 6.130\n",
      "Every effort moves you know he had been his pictures, and I felt it's by his last word.                   \"Oh, and he had been the end, and he had been\n",
      "Ep 6 (Step 000045): Train loss 3.530, Val loss 6.183\n",
      "Ep 6 (Step 000050): Train loss 2.960, Val loss 6.123\n",
      "Every effort moves you know it was his pictures--I glanced after him, I had the last word.        \"Oh, and I was his pictures--I looked.   \"I looked. \"I looked. \n",
      "Ep 7 (Step 000055): Train loss 2.832, Val loss 6.150\n",
      "Ep 7 (Step 000060): Train loss 2.104, Val loss 6.133\n",
      "Every effort moves you know the picture to me--I glanced after him, and Mrs.  \"I was no great, the fact, the fact that, the moment--as Jack himself, as his pictures--as of the picture--because he was a little\n",
      "Ep 8 (Step 000065): Train loss 1.691, Val loss 6.186\n",
      "Ep 8 (Step 000070): Train loss 1.391, Val loss 6.230\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little: \"Yes--and by me to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.059, Val loss 6.251\n",
      "Ep 9 (Step 000080): Train loss 0.800, Val loss 6.278\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back the window-curtains, I saw that, and down the room, and now\n",
      "Ep 10 (Step 000085): Train loss 0.569, Val loss 6.373\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "# 注意：\n",
    "# 取消注释以下代码以计算执行时间\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 注意：\n",
    "# 取消注释以下代码以显示执行时间\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204",
   "metadata": {},
   "source": [
    "- 注意，你的计算机上获得的损失值可能会略有不同，如果它们大致相似（训练损失低于 1，验证损失低于 7），则无需担心\n",
    "- 微小的差异通常是由于不同的 GPU 硬件和 CUDA 版本或较新 PyTorch 版本中的微小变化引起的\n",
    "- 即使你在 CPU 上运行该示例，你也可能会观察到微小的差异；产生差异的一个可能原因是 `nn.Dropout` 在不同操作系统上的行为不同，这取决于 PyTorch 是如何编译的，正如 [PyTorch 问题跟踪器上的此处](https://github.com/pytorch/pytorch/issues/121595) 所讨论的那样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0WSRu2i0iHJE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0WSRu2i0iHJE",
    "outputId": "9d36c61b-517d-4f07-a7e8-4563aff78b11"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # 绘制训练和验证损失随 epoch 的变化\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # 仅在 x 轴上显示整数标签\n",
    "\n",
    "    # 为看到的 token 创建第二个 x 轴\n",
    "    ax2 = ax1.twiny()  # 创建一个共享相同 y 轴的第二个 x 轴\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 用于对齐刻度的不可见图\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # 调整布局以腾出空间\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
   "metadata": {},
   "source": [
    "- 观察上面的结果，我们可以看到模型开始时生成的是难以理解的单词串，而在最后，它能够产生语法上或多或少正确的句子\n",
    "- 然而，基于训练集和验证集的损失，我们可以看到模型开始过拟合\n",
    "- 如果我们检查它在最后写的一些段落，我们会发现它们逐字包含在训练集中——它只是记住了训练数据\n",
    "- 随后，我们将介绍可以在一定程度上减轻这种记忆的解码策略\n",
    "- 请注意，这里的过拟合是因为我们有一个非常非常小的训练集，并且我们对它进行了多次迭代\n",
    "  - 这里的 LLM 训练主要用于教育目的；我们主要想看看模型能否学会产生连贯的文本\n",
    "  - 我们稍后将加载预训练权重，而不是花费数周或数月的时间在昂贵的硬件上针对大量数据训练此模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/13.webp\" width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de713235-1561-467f-bf63-bf11ade383f0",
   "metadata": {},
   "source": [
    "**If you are interested in augmenting this training function with more advanced techniques, such as learning rate warmup, cosine annealing, and gradient clipping, please refer to [Appendix D](../../appendix-D/01_main-chapter-code)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
   "metadata": {},
   "source": [
    "**如果你对更大的训练数据集和更长的训练运行时间感兴趣，请参阅 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
   "metadata": {
    "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
   },
   "source": [
    "## 5.3 控制随机性的解码策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
   "metadata": {},
   "source": [
    "- 对于像我们上面训练的 GPT 模型这样相对较小的 LLM，推理成本相对较低，所以如果你在上面使用 GPU 进行训练，在推理时也没必要使用 GPU\n",
    "- 使用我们之前在简单训练函数中使用的 `generate_text_simple` 函数（来自上一章），我们可以一次生成一个单词（或 token）的新文本\n",
    "- 正如第 5.1.2 节所解释的那样，下一个生成的 token 是词表中所有 token 中概率分数最大的 token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 新增：这里使用 CPU，因为对于这个模型来说推理成本很低\n",
    "# 并且为了确保读者在本书的剩余部分\n",
    "# 获得相同的结果\n",
    "inference_device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(inference_device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
   "metadata": {},
   "source": [
    "- 即使我们多次执行上面的 `generate_text_simple` 函数，LLM 也总是会生成相同的输出\n",
    "- 我们现在介绍两个概念，即所谓的解码策略，来修改 `generate_text_simple`：*温度缩放（temperature scaling）*和 *top-k* 采样\n",
    "- 这些将允许模型控制生成文本的随机性和多样性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
   "metadata": {},
   "source": [
    "### 5.3.1 温度缩放 (Temperature scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
   "metadata": {},
   "source": [
    "- 以前，我们总是使用 `torch.argmax` 采样概率最高的 token 作为下一个 token\n",
    "- 为了增加多样性，我们可以使用 `torch.multinomial(probs, num_samples=1)` 从概率分布中采样下一个 token\n",
    "- 在这里，每个索引被选中的机会对应于它在输入张量中的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
   "metadata": {},
   "source": [
    "- 下面简要回顾一下生成下一个 token 的过程，假设使用一个非常小的词表用于说明目的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# 假设输入是 \"every effort moves you\"，并且 LLM\n",
    "# 返回下一个 token 的以下 logits：\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# 下一个生成的 token 如下：\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
   "metadata": {},
   "source": [
    "- 我们不使用 `torch.argmax` 来确定最可能的 token，而是使用 `torch.multinomial(probas, num_samples=1)` 通过从 softmax 分布中采样来确定最可能的 token\n",
    "- 出于说明目的，让我们看看使用原始 softmax 概率对下一个 token 进行 1,000 次采样时会发生什么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # 为了可重复性设置手动种子\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
   "metadata": {},
   "source": [
    "- 我们可以通过一个称为温度缩放（temperature scaling）的概念来控制分布和选择过程\n",
    "- “温度缩放”只是一个花哨的词，意思是将 logits 除以一个大于 0 的数\n",
    "- 大于 1 的温度将导致应用 softmax 后的 token 概率分布更加均匀\n",
    "- 小于 1 的温度将导致应用 softmax 后的分布更加自信（更尖锐或更陡峭）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b5399",
   "metadata": {},
   "source": [
    "- 请注意，根据你的操作系统，生成的 dropout 输出看起来可能会有所不同；你可以在 [PyTorch 问题跟踪器上的此处](https://github.com/pytorch/pytorch/issues/121595) 阅读有关这种不一致性的更多信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# 温度值\n",
    "temperatures = [1, 0.1, 5]  # 原始、更高置信度、更低置信度\n",
    "\n",
    "# 计算缩放后的概率\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘图\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'温度 = {T}')\n",
    "\n",
    "ax.set_ylabel('概率')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
   "metadata": {},
   "source": [
    "- 我们可以看到，通过温度 0.1 进行的缩放导致了更尖锐的分布，接近于 `torch.argmax`，使得最可能的单词几乎总是被选中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "985 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "15 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
   "metadata": {},
   "source": [
    "- 通过温度 5 缩放的概率分布更加均匀："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
   "metadata": {},
   "source": [
    "- 假设 LLM 输入为：\"every effort moves you\"，使用上述方法有时会产生无意义的文本，例如 \"every effort moves you pizza\"，发生概率为 3.2%（1000 次中有 32 次）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k 采样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
   "metadata": {},
   "source": [
    "- 为了能够使用更高的温度来增加输出的多样性，并减少出现无意义句子的概率，我们可以将采样 token 限制为前 k 个最可能的 token："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/15.webp\" width=500px>\n",
    "\n",
    "- （请注意，此图中的数字已被截断为小数点后两位，以减少视觉混乱。Softmax 行中的值加起来应为 1.0。）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
   "metadata": {},
   "source": [
    "- 在代码中，我们可以按如下方式实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00",
   "metadata": {},
   "source": [
    "> 注意：\n",
    ">\n",
    ">  前一个代码单元格的一种替代的、稍微更高效的实现如下：\n",
    ">\n",
    "> ```python\n",
    "> new_logits = torch.full_like( # create tensor containing -inf values\n",
    ">    next_token_logits, -torch.inf\n",
    ">)   \n",
    "> new_logits[top_pos] = next_token_logits[top_pos] # copy top k values into the -inf tensor\n",
    "> ```\n",
    "> <br>\n",
    "> 更多详情请见： https://github.com/rasbt/LLMs-from-scratch/discussions/326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
   "metadata": {},
   "source": [
    "### 5.3.3 修改文本生成函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34770423-473d-46f6-a5fa-6b2979564d26",
   "metadata": {},
   "source": [
    "- 前两个小节介绍了温度采样和 top-k 采样\n",
    "- 让我们使用这两个概念来修改第 4 章中的 `generate_text_simple` 函数，创建一个新的 `generate` 函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For 循环与之前相同：获取 logits，并仅关注最后一个时间步\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # 新增：使用 top_k 采样过滤 logits\n",
    "        if top_k is not None:\n",
    "            # 仅保留 top_k 值\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # 新增：应用温度缩放\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # 新增（书中未提及）：获得 mps 设备上等效结果的数值稳定性技巧\n",
    "            # 在 softmax 之前减去行最大值\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "            \n",
    "            # 应用 softmax 以获取概率\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # 从分布中采样\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # 否则与之前相同：获取具有最高 logits 值的词汇表条目的索引\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # 如果遇到序列结束 token 且指定了 eos_id，则提前停止生成\n",
    "            break\n",
    "\n",
    "        # 与之前相同：将采样索引追加到运行序列中\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand,\" she down.\" For Mrs. Gisburn! The women had\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
   "metadata": {},
   "source": [
    "## 5.4 在 PyTorch 中加载和保存模型权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc52676-f026-4566-a226-2a90269f9d53",
   "metadata": {},
   "source": [
    "- 训练 LLM 的计算成本很高，因此能够保存和加载 LLM 权重至关重要\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/16.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
   "metadata": {},
   "source": [
    "- PyTorch 中推荐的方法是保存模型权重，即所谓的 `state_dict`，方法是对 `.state_dict()` 方法应用 `torch.save` 函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
   "metadata": {},
   "source": [
    "- 然后我们可以按如下方式将模型权重加载到新的 `GPTModel` 模型实例中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
   "metadata": {},
   "source": [
    "- 通常使用自适应优化器（如 Adam 或 AdamW）而不是常规 SGD 来训练 LLM\n",
    "- 这些自适应优化器为每个模型权重存储额外的参数，因此如果我们计划稍后继续预训练，那么保存它们是有意义的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a0c7295-c822-43bf-9286-c45abc542868",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194350e-0409-4a63-8ffd-d3a896509032",
   "metadata": {},
   "source": [
    "## 5.5 加载 OpenAI 的预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
   "metadata": {},
   "source": [
    "- 之前，出于教育目的，我们仅使用非常短的短篇小说书训练了一个小型 GPT-2 模型\n",
    "- 有兴趣的读者也可以在 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg) 中找到在完整的古腾堡计划书籍语料库上进行的更长的预训练运行\n",
    "- 幸运的是，我们不必花费数万到数十万美元在大型预训练语料库上预训练模型，而是可以加载 OpenAI 提供的预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "⚠️ **注意：某些用户在本节中可能会因 TensorFlow 兼容性问题而遇到问题，尤其是在某些 Windows 系统上。此处 TensorFlow 仅用于加载原始 OpenAI GPT-2 权重文件，然后我们将这些文件转换为 PyTorch。如果您遇到与 TensorFlow 相关的问题，可以使用下面的替代代码代替本节中的其余代码。**\n",
    "此替代方案基于预转换的 PyTorch 权重，使用上一节中描述的相同转换过程创建。详情请参阅笔记本：\n",
    "[../02_alternative_weight_loading/weight-loading-pytorch.ipynb](../02_alternative_weight_loading/weight-loading-pytorch.ipynb)\n",
    "\n",
    "```python\n",
    "file_name = \"gpt2-small-124M.pth\"\n",
    "# file_name = \"gpt2-medium-355M.pth\"\n",
    "# file_name = \"gpt2-large-774M.pth\"\n",
    "# file_name = \"gpt2-xl-1558M.pth\"\n",
    "\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")\n",
    "\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "gpt.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "gpt.to(device);\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cab892-a165-4f43-9601-f517bc212ab6",
   "metadata": {},
   "source": [
    "- 首先，一些样板代码用于从 OpenAI 下载文件并将权重加载到 Python 中\n",
    "- 由于 OpenAI 使用了 [TensorFlow](https://www.tensorflow.org/)，我们将不得不安装并使用 TensorFlow 来加载权重；[tqdm](https://github.com/tqdm/tqdm) 是一个进度条库\n",
    "- 取消注释并运行下一个单元格以安装所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从该文件夹中包含的 gpt_download.py 进行相对导入\n",
    "\n",
    "from gpt_download import download_and_load_gpt2\n",
    "# 或者：\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**注意**\n",
    "\n",
    "- 在极少数情况下，上面的代码单元格可能会导致 `zsh: illegal hardware instruction python` 错误，这可能是由于你机器上的 TensorFlow 安装问题\n",
    "- 一位读者发现通过 `conda` 安装 TensorFlow 解决了这个特定情况下的问题，如 [此处](https://github.com/rasbt/LLMs-from-scratch/discussions/273#discussioncomment-12367888) 所述\n",
    "- 你可以在这个补充的 [Python 设置教程](https://github.com/rasbt/LLMs-from-scratch/tree/main/setup/01_optional-python-setup-preferences#option-2-using-conda) 中找到更多说明\n",
    "\n",
    "---\n",
    "\n",
    "- 然后我们可以按如下方式下载 1.24 亿参数模型的模型权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"设置:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"参数字典键:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token 嵌入权重张量维度:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e100c-294e-4afc-a70a-2f398ac4c104",
   "metadata": {},
   "source": [
    "- 或者，\"355M\"、\"774M\" 和 \"1558M\" 也是支持的 `model_size` 参数\n",
    "- 这些不同大小的模型之间的差异总结在下图中："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f19d32-5aae-4176-9f86-f391672c8f0d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/17.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41",
   "metadata": {},
   "source": [
    "- 上面，我们将 124M GPT-2 模型权重加载到了 Python 中，但是我们仍然需要将它们传输到我们的 `GPTModel` 实例中\n",
    "- 首先，我们初始化一个新的 GPTModel 实例\n",
    "- 请注意，原始 GPT 模型在多头注意力模块中为查询、键和值矩阵初始化了带偏置向量的线性层，这不是必需的或推荐的；但是，为了能够正确加载权重，我们也必须在我们的实现中通过将 `qkv_bias` 设置为 `True` 来启用它们\n",
    "- 我们还使用了原始 GPT-2 模型使用的 `1024` token 上下文长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef90dd-0654-4667-844f-08e28339ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在字典中定义模型配置以使其紧凑\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# 复制基本配置并使用特定模型设置进行更新\n",
    "model_name = \"gpt2-small (124M)\"  # 示例模型名称\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f29ac-8342-4b3d-a57d-9b0166ced314",
   "metadata": {},
   "source": [
    "- 下一个任务是将 OpenAI 权重分配给我们 `GPTModel` 实例中相应的权重张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a92229-c002-49a6-8cfb-248297ad8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7472cb-54dc-4311-96d8-b2694f885cee",
   "metadata": {},
   "source": [
    "- 如果模型加载正确，我们可以使用它来使用我们之前的 `generate` 函数生成新文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d079f98-a7c4-462e-8416-5a64f670861c",
   "metadata": {},
   "source": [
    "- 我们知道我们正确加载了模型权重，因为模型可以生成连贯的文本；如果我们犯了一个小错误，模型就无法做到这一点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
   "metadata": {},
   "source": [
    "- 有关从 Hugging Face Hub 加载权重的替代方法，请参阅 [../02_alternative_weight_loading](../02_alternative_weight_loading)\n",
    "- 如果你有兴趣了解 GPT 架构与 Llama 架构（Meta AI 开发的一种流行 LLM）的比较，请参阅 [../07_gpt_to_llama](../07_gpt_to_llama) 中的奖励内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
   "metadata": {},
   "source": [
    "## 总结和要点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
   "metadata": {},
   "source": [
    "- 请参阅 [./gpt_train.py](./gpt_train.py) 脚本，这是一个自包含的训练脚本\n",
    "- [./gpt_generate.py](./gpt_generate.py) 脚本加载来自 OpenAI 的预训练权重并根据提示生成文本\n",
    "- 你可以在 [./exercise-solutions.ipynb](./exercise-solutions.ipynb) 中找到练习解答"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
